# Story 2.7: GLM API集成与并发控制

## Status
Draft

## Story
**As a** 平台开发者,
**I want** 集成GLM API进行AI内容处理，并实现严格的并发控制和重试机制,
**so that** 我们可以在控制成本的同时，确保AI处理的稳定性和可靠性

## Acceptance Criteria
- [ ] 集成GLM API替代Cloudflare Workers AI服务
- [ ] 实现严格的并发控制（最大并发数为1，确保稳定性和成本控制）
- [ ] 支持智能重试机制，处理API调用失败和超时情况
- [ ] 实现请求队列管理，避免API调用冲突
- [ ] 提供详细的API调用监控和日志记录
- [ ] 支持多种GLM模型选择和配置
- [ ] 实现成本控制和用量统计功能
- [ ] 确保与现有内容处理流程的无缝集成

## Tasks / Subtasks
- [ ] Task 1: 设计GLM API集成架构 (AC: 1, 4, 8)
  - [ ] 设计GLM API客户端和服务封装
  - [ ] 实现配置管理和模型选择机制
  - [ ] 创建请求队列和并发控制系统
  - [ ] 集成到现有内容处理流程
- [ ] Task 2: 实现并发控制机制 (AC: 2, 4, 7)
  - [ ] 开发基于Semaphore的并发控制
  - [ ] 实现请求队列和优先级管理
  - [ ] 创建API调用限流和熔断机制
  - [ ] 实现动态并发数调整功能
- [ ] Task 3: 开发重试和错误处理 (AC: 3, 5, 7)
  - [ ] 实现指数退避重试策略
  - [ ] 创建错误分类和处理机制
  - [ ] 开发超时和异常处理逻辑
  - [ ] 实现失败请求的重新排队功能
- [ ] Task 4: 集成监控和统计 (AC: 5, 7)
  - [ ] 创建API调用监控指标
  - [ ] 实现成本统计和用量分析
  - [ ] 开发性能监控和报警机制
  - [ ] 创建详细日志记录和追踪系统
- [ ] Task 5: 优化和测试 (AC: 6, 8)
  - [ ] 实现模型性能测试和比较
  - [ ] 优化请求处理和响应时间
  - [ ] 进行压力测试和稳定性验证
  - [ ] 创建故障恢复和降级策略

## Dev Notes

### 技术架构信息
- **AI服务**: GLM API (替代Cloudflare Workers AI)
- **并发控制**: Semaphore + 请求队列模式
- **重试机制**: 指数退避 + 智能错误处理
- **监控**: 实时指标 + 成本统计 + 详细日志
- **队列**: Cloudflare Queues (付费版) 支持异步处理
- **存储**: 成本数据和统计信息存储在D1数据库

### 关键设计原则
- **稳定性优先**: 并发数为1，避免API调用冲突
- **成本控制**: 详细用量统计和监控
- **容错处理**: 完善的重试和降级机制
- **可观测性**: 全面的监控和日志记录

### 数据模型信息
```typescript
// GLM API配置
interface GLMConfig {
  id: string;
  apiKey: string;
  baseUrl: string;
  model: string;
  maxTokens: number;
  temperature: number;
  timeout: number;
  maxRetries: number;
  isActive: boolean;
  createdAt: Date;
  updatedAt: Date;
}

// API调用统计
interface GLMUsageStats {
  id: string;
  date: string;
  totalCalls: number;
  successfulCalls: number;
  failedCalls: number;
  totalTokens: number;
  totalCost: number;
  averageResponseTime: number;
  model: string;
  createdAt: Date;
}

// 请求队列项目
interface GLMRequestQueue {
  id: string;
  userId: string;
  contentId: string;
  prompt: string;
  model: string;
  priority: number;
  status: 'pending' | 'processing' | 'completed' | 'failed';
  retryCount: number;
  maxRetries: number;
  nextRetryAt?: Date;
  errorMessage?: string;
  result?: GLMResponse;
  createdAt: Date;
  processedAt?: Date;
}

// API调用日志
interface GLMCallLog {
  id: string;
  requestId: string;
  userId: string;
  endpoint: string;
  model: string;
  request: {
    prompt: string;
    parameters: Record<string, any>;
  };
  response: {
    success: boolean;
    data?: any;
    error?: string;
    statusCode: number;
    responseTime: number;
    tokensUsed: number;
  };
  cost: number;
  retryCount: number;
  timestamp: Date;
}

// GLM API响应
interface GLMResponse {
  id: string;
  object: string;
  created: number;
  model: string;
  choices: {
    index: number;
    message: {
      role: string;
      content: string;
    };
    finish_reason: string;
  }[];
  usage: {
    prompt_tokens: number;
    completion_tokens: number;
    total_tokens: number;
  };
}
```

### API规范信息
```typescript
// GLM管理API
interface GLMAPI {
  // 获取GLM配置
  GET /api/admin/glm/config: {
    response: { config: GLMConfig };
  }
  
  // 更新GLM配置
  PUT /api/admin/glm/config: {
    body: Partial<GLMConfig>;
    response: { config: GLMConfig };
  }
  
  // 获取API调用统计
  GET /api/admin/glm/statistics: {
    query: { 
      startDate?: string;
      endDate?: string;
      model?: string;
    };
    response: { statistics: GLMUsageStats[] };
  }
  
  // 获取请求队列状态
  GET /api/admin/glm/queue: {
    query: { 
      status?: string;
      limit?: number;
    };
    response: { queue: GLMRequestQueue[]; total: number };
  }
  
  // 手动重试失败请求
  POST /api/admin/glm/retry/:requestId: {
    response: { success: boolean };
  }
  
  // 获取实时监控指标
  GET /api/admin/glm/metrics: {
    response: {
      currentConcurrency: number;
      queueLength: number;
      recentCalls: GLMCallLog[];
      errorRate: number;
      averageResponseTime: number;
    };
  }
}

// 内部服务接口
interface GLMService {
  // 发送GLM请求
  callGLM(params: {
    prompt: string;
    model?: string;
    userId: string;
    contentId?: string;
    priority?: number;
  }): Promise<GLMResponse>;
  
  // 获取队列状态
  getQueueStatus(): Promise<{
    pending: number;
    processing: number;
    completed: number;
    failed: number;
  }>;
  
  // 获取API统计
  getUsageStats(params: {
    startDate: string;
    endDate: string;
  }): Promise<GLMUsageStats[]>;
}
```

### 并发控制实现
```typescript
// 并发控制器
class GLMConcurrencyController {
  private semaphore: Semaphore;
  private queue: PriorityQueue<GLMRequest>;
  private activeRequests: Map<string, Promise<GLMResponse>>;
  
  constructor(maxConcurrency: number = 1) {
    this.semaphore = new Semaphore(maxConcurrency);
    this.queue = new PriorityQueue();
    this.activeRequests = new Map();
  }
  
  async execute(request: GLMRequest): Promise<GLMResponse> {
    // 获取信号量许可
    const release = await this.semaphore.acquire();
    
    try {
      // 执行API调用
      const result = await this.executeWithRetry(request);
      return result;
    } finally {
      // 释放信号量
      release();
    }
  }
  
  private async executeWithRetry(request: GLMRequest): Promise<GLMResponse> {
    let retryCount = 0;
    const maxRetries = request.maxRetries || 3;
    
    while (retryCount <= maxRetries) {
      try {
        const response = await this.callGLMAPI(request);
        return response;
      } catch (error) {
        retryCount++;
        
        if (retryCount > maxRetries) {
          throw error;
        }
        
        // 指数退避
        const delay = Math.min(1000 * Math.pow(2, retryCount), 30000);
        await this.sleep(delay);
      }
    }
  }
}
```

### 重试机制设计
```typescript
// 重试策略配置
interface RetryStrategy {
  maxRetries: number;
  baseDelay: number;
  maxDelay: number;
  backoffMultiplier: number;
  retryableErrors: string[];
}

// 智能重试器
class GLMRetryHandler {
  private strategy: RetryStrategy;
  
  constructor(strategy: RetryStrategy) {
    this.strategy = strategy;
  }
  
  shouldRetry(error: any, attempt: number): boolean {
    if (attempt >= this.strategy.maxRetries) {
      return false;
    }
    
    // 检查错误类型是否可重试
    const errorType = this.getErrorType(error);
    return this.strategy.retryableErrors.includes(errorType);
  }
  
  getDelay(attempt: number): number {
    const delay = this.strategy.baseDelay * 
                  Math.pow(this.strategy.backoffMultiplier, attempt);
    return Math.min(delay, this.strategy.maxDelay);
  }
  
  private getErrorType(error: any): string {
    if (error.code === 'TIMEOUT') return 'timeout';
    if (error.code === 'RATE_LIMIT') return 'rate_limit';
    if (error.code === 'NETWORK_ERROR') return 'network_error';
    if (error.code === 'SERVER_ERROR') return 'server_error';
    return 'unknown';
  }
}
```

### 技术栈信息
- **AI服务**: GLM API with HTTP client
- **并发控制**: 自定义Semaphore实现
- **队列**: Cloudflare Queues (付费版) + 优先级队列
- **数据库**: Cloudflare D1 with Drizzle ORM
- **监控**: 自定义指标 + Cloudflare Analytics
- **重试**: 指数退避算法
- **日志**: 结构化日志记录
- **执行环境**: Cloudflare Workers (付费版) - 默认30秒CPU时间，可配置最长5分钟

### 文件路径和命名约定
- GLM服务: `/backend/src/services/ai/`
  - `glm-client.ts` - GLM API客户端
  - `glm-service.ts` - GLM服务封装
  - `concurrency-controller.ts` - 并发控制器
  - `retry-handler.ts` - 重试处理器
  - `glm-queue.ts` - 请求队列管理
- 监控统计: `/backend/src/services/monitoring/`
  - `glm-monitor.ts` - GLM监控服务
  - `cost-tracker.ts` - 成本追踪服务
- API路由: `/backend/src/routes/`
  - `admin/glm.ts` - GLM管理API
- 数据库: `/backend/src/db/schema.ts` (扩展)
- 配置: `/backend/src/config/glm.config.ts`

### 技术约束
- 必须严格控制并发数为1，确保API调用稳定性
- 必须实现完善的错误处理和重试机制
- 必须提供详细的成本统计和监控
- 必须支持动态配置和模型切换
- 必确保保请求处理的顺序性和一致性
- 必须实现超时控制和熔断机制
- Cloudflare Workers付费版提供充足的CPU时间：默认30秒，可配置最长5分钟
- Cron触发器最长支持15分钟CPU时间，完全满足复杂的GLM API调用需求

### CPU时间配置示例
```json
// wrangler.jsonc - 配置更长的CPU时间
{
  "name": "glm-api-worker",
  "main": "src/index.ts",
  "compatibility_date": "2025-02-11",
  "limits": {
    "cpu_ms": 300000  // 5分钟CPU时间（可选）
  }
}
```

### CPU时间使用建议
- **常规HTTP请求**：默认30秒足够处理大多数GLM API调用
- **批量处理**：可配置2-3分钟CPU时间
- **复杂分析任务**：可配置5分钟CPU时间
- **Cron触发器**：可使用最长15分钟CPU时间进行大规模处理

## Testing

### 测试标准
- 并发控制有效，无API调用冲突
- 重试机制可靠，能够处理各种错误情况
- 队列管理高效，优先级正确
- 成本统计准确，用量监控实时
- 错误处理完善，系统稳定性好
- 性能满足要求，响应时间合理

### 测试框架和模式
- **单元测试**: 使用Vitest测试并发控制和重试逻辑
- **集成测试**: 使用Playwright测试完整的GLM调用流程
- **压力测试**: 测试高并发情况下的系统稳定性
- **错误测试**: 模拟各种API错误和异常情况
- **性能测试**: 测试响应时间和吞吐量

### 测试用例示例
```typescript
// 并发控制测试
describe('GLM Concurrency Controller', () => {
  it('should limit concurrent requests to max concurrency', async () => {
    const controller = new GLMConcurrencyController(1);
    const results: Promise<GLMResponse>[] = [];
    
    // 同时发送多个请求
    for (let i = 0; i < 5; i++) {
      results.push(controller.execute({
        prompt: `Test prompt ${i}`,
        model: 'glm-4',
        userId: 'test-user',
        contentId: `content-${i}`
      }));
    }
    
    // 验证所有请求最终都完成
    const resolved = await Promise.all(results);
    expect(resolved).toHaveLength(5);
  });
  
  it('should handle API failures with retry', async () => {
    const mockGLMClient = createMockGLMClient();
    mockGLMClient.simulateFailure(new Error('API Error'), 2);
    
    const service = new GLMService(mockGLMClient);
    const result = await service.callGLM({
      prompt: 'Test prompt',
      model: 'glm-4',
      userId: 'test-user'
    });
    
    expect(result).toBeDefined();
    expect(mockGLMClient.callCount).toBe(3); // 1次初始 + 2次重试
  });
});

// 成本统计测试
describe('GLM Cost Tracking', () => {
  it('should accurately calculate API costs', async () => {
    const tracker = new CostTracker();
    
    await tracker.recordCall({
      model: 'glm-4',
      tokens: 1000,
      duration: 2000,
      success: true
    });
    
    const stats = await tracker.getDailyStats();
    expect(stats.totalCost).toBeGreaterThan(0);
    expect(stats.totalTokens).toBe(1000);
  });
});
```

### 性能测试
```typescript
// 性能基准测试
describe('GLM Performance Benchmarks', () => {
  it('should handle 100 requests within acceptable time', async () => {
    const service = new GLMService();
    const startTime = Date.now();
    
    const requests = Array.from({ length: 100 }, (_, i) => 
      service.callGLM({
        prompt: `Benchmark prompt ${i}`,
        model: 'glm-4',
        userId: 'test-user',
        contentId: `benchmark-${i}`
      })
    );
    
    await Promise.all(requests);
    const totalTime = Date.now() - startTime;
    
    expect(totalTime).toBeLessThan(300000); // 5分钟内完成
  });
});
```

## Change Log
| Date | Version | Description | Author |
| ---- | ------- | ----------- | ------ |
| 2025-09-14 | 1.0 | Initial draft | Development Team |

## Dev Agent Record
### Agent Model Used
Claude Sonnet 4

### Debug Log References
1. 待开发 - 设计GLM API集成架构
2. 待开发 - 实现并发控制机制
3. 待开发 - 开发重试和错误处理
4. 待开发 - 集成监控和统计
5. 待开发 - 优化和测试
6. 待开发 - 性能调优和稳定性验证
7. 待开发 - 文档和部署准备

### Completion Notes List
1. 待开发 - 完成GLM API客户端和服务封装
2. 待开发 - 实现并发控制和队列管理
3. 待开发 - 开发重试机制和错误处理
4. 待开发 - 集成监控和成本统计
5. 待开发 - 完成性能优化和测试
6. 待开发 - 创建文档和部署指南
7. 待开发 - 进行集成测试和验证
8. 待开发 - 准备生产环境部署

### File List
- 待创建 - `/backend/src/services/ai/glm-client.ts`
- 待创建 - `/backend/src/services/ai/glm-service.ts`
- 待创建 - `/backend/src/services/ai/concurrency-controller.ts`
- 待创建 - `/backend/src/services/ai/retry-handler.ts`
- 待创建 - `/backend/src/services/ai/glm-queue.ts`
- 待创建 - `/backend/src/services/monitoring/glm-monitor.ts`
- 待创建 - `/backend/src/services/monitoring/cost-tracker.ts`
- 待创建 - `/backend/src/routes/admin/glm.ts`
- 待创建 - `/backend/src/config/glm.config.ts`
- 待更新 - `/backend/src/db/schema.ts` (添加GLM相关表)
- 待创建 - `/backend/src/db/migrations/2025-09-14-add-glm-integration.sql`

### Change Log
| Date | Version | Description | Author |
| ---- | ------- | ----------- | ------ |
| 2025-09-14 | 1.0 | Initial draft | Development Team |

## QA Results
### QA Agent Used
待定

### QA Checklist
- [ ] 并发控制有效，无API调用冲突
- [ ] 重试机制可靠，能够处理各种错误情况
- [ ] 队列管理高效，优先级正确
- [ ] 成本统计准确，用量监控实时
- [ ] 错误处理完善，系统稳定性好
- [ ] 性能满足要求，响应时间合理
- [ ] 集成测试通过
- [ ] 安全性测试通过
- [ ] 文档完整性验证

### QA Notes
待执行QA测试...

### QA Status
待开发 - Pending Development